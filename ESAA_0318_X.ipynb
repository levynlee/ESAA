{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdc1ef0-e85e-4497-9562-6ddb1c77cad6",
   "metadata": {},
   "source": [
    "# Chapter 3. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ec3c4-88ca-4445-90dc-8bae230fb065",
   "metadata": {},
   "source": [
    "- 머신러닝 모델은 여러 방법으로 예측 성능 평가함\n",
    "- 성능 평가 지표\n",
    "  - 회귀\n",
    "    - 실제값과 예측값의 오차 평균값에 기반\n",
    "  - 분류\n",
    "    - 이진 분류: 결정 클래스 값 종류의 유형에 따라 긍정/부정과 같은 2개의 결괏값만 가짐\n",
    "    - 멀티 분류: 여러 개의 결정 클래스 값을 가짐\n",
    "    - 분류의 성능 평가 지표\n",
    "      - 정확도(Accuracy)\n",
    "      - 오차행렬(Confusion Matrix)\n",
    "      - 정밀도(Precision)\n",
    "      - 재현율(Recall)\n",
    "      - F1 스코어\n",
    "      - ROC AUC\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff434b65-3f59-4683-b648-7348f9e37f1f",
   "metadata": {},
   "source": [
    "## 1. 정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfa674-759c-4e95-b5c3-d4ad4393f696",
   "metadata": {},
   "source": [
    "- 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표\n",
    "- (예측 결과가 동일한 데이터 건수) / (전체 예측 데이터 건수)\n",
    "- 직관적으로 모델 예측 성능을 나타내는 평가 지표\n",
    "- BUT 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능 왜곡할 가능성 있음 => 정확도 외 다른 수치와 함께 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ec0aba-edcf-4e0a-9d7f-efa56a61ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fit() 메서드는 아무 것도 수행하지 않고, predict()는 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측하는 단순한 분류기 생성\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit 메서드는 아무것도 학습하지 않음\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    # predict 메서드는 단순히 Sex 피처가 1이면 0, 아니면 1로 예측\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( (X.shape[0],1) )\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1 \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e76106b0-a941-428d-8b72-ae9cf82d5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.3855\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv(r'C:\\Users\\이희원\\OneDrive\\바탕 화면\\EWHA\\4-1\\ESAA\\kaggle_data\\titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "782d3e14-10c8-498f-b370-2593eeaba9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    # 입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0값으로 만들어서 변환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "# 사이킷런의 내장 데이터 세트인 load_digits()를 이용해 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "# digits 번호가 7번이면 True고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb71e8-2467-44ba-9cdb-eb3be8bb7c92",
   "metadata": {},
   "source": [
    "- 불균형한 데이터로 생성한 y_test의 데이터 분포도를 확인\n",
    "- MyFakeClassifier를 이용해 예측과 평가 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01538cd1-ce21-4461-9405-034cbf8bde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기: (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "Name: count, dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는: 0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 세트 크기:', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는: {:.3f}'.format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c8cf44-81a3-4e1d-ac9b-f8220e01666a",
   "metadata": {},
   "source": [
    "- 이처럼 정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용해서는 안 됨\n",
    "- 정확도의 분류 평가 지표로서의 한계를 극복하기 위해 다른 분류 지표들과 함께 적용해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b307f-bfc9-4765-a260-523fa47e2c99",
   "metadata": {},
   "source": [
    "## 2. 오차 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741774cd-9cf4-495a-8a10-6c8b1a06af4f",
   "metadata": {},
   "source": [
    "- 오차행렬 = confusion matrix = 혼동행렬\n",
    "- 이진 분류에서 성능 지표로 잘 활용됨\n",
    "- 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고(confused) 있는지도 함께 보여주는 지표\n",
    "- [이진 분류의 예측 오류가 얼마인지 + 어떤 유형의 예측 오류가 발생하고 있는지]를 함께 나타내는 지표\n",
    "- 4분면(TN, FP, FN, TP) 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떤 유형을 가지고 매핑되는지 나타냄\n",
    "- ex. TN: True Negative; 'True = 예측 클래스 값과 실제 클래스 값이 같다', 'Negative = 예측값이 negative 값이다'; 예측을 negative 값 0(부정)으로 예측했는데, 실제 값도 negative 값 0(부정)이라는 의미\n",
    "- sklearn은 오차행렬을 구하기 위해 confusion_matrix() API 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90caa6-3c11-496c-8feb-b53834fa0fdc",
   "metadata": {},
   "source": [
    "- MyFakeClassifier의 예측 결과인 fakepred\n",
    "- 실제 결과인 y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ece66ee7-e137-4055-bd8c-b80d0a23c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533bc9c7-82ed-4e91-90a5-46bee1e77927",
   "metadata": {},
   "source": [
    "- TN: array[0,0] = 405\n",
    "- FP: array[0,1] = 0\n",
    "- FN: array[1,0] = 45\n",
    "- TP: array[1,1] = 0\n",
    "- 테스트 데이터 세트의 클래스 값 분포는 0이 405건, 1이 45건\n",
    "- TP, TN, FP, FN 값을 조합해 Classifier의 성능을 추정할 수 있는 주요 지표인 정확도, 정밀도, 재현율 값을 알 수 있음\n",
    "- 정확도의 오차 행렬상에서의 재정의\n",
    "  - 예측 결과와 실제 값이 동일한 건수/전체 데이터 수 = (TN + TP)/(TN + FP + FN + TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9ee3b-a1c6-4674-9cb1-ec4be351d96e",
   "metadata": {},
   "source": [
    "## 3. 정밀도와 재현율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e7e80-c19f-4df0-af0e-10c12f2ca9d5",
   "metadata": {},
   "source": [
    "- 불균형한 데이터 세트에서 정확도보다 더 선호되는 평가 지표\n",
    "- Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표\n",
    "- 정밀도\n",
    "  - TP / (FP + TP)\n",
    "  - 예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "  - Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표\n",
    "  - 양성 예측도라고도 함\n",
    "  - TP 높이기 + FP 낮추기에 초점\n",
    "- 재현율\n",
    "  - TP / (FN + TP)\n",
    "  - 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "  - 민감도(Sensitivity) 또는 TPR(True Positive Rate)라고도 불림\n",
    "  - TP 높이기 + FN 낮추기에 초점\n",
    "- 정밀도가 중요 지표인 경우\n",
    "  - 실제 Negative 음성인 데이터 예특을 Positive 양성으로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
    "  - ex. 스팸메일 여부를 판단하는 모델\n",
    "- 재현율이 중요 지표인 경우\n",
    "  - 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
    "  - ex. 암 판단 모델\n",
    "  - ex. 보험 사기와 같은 금융 사기 적발 모델\n",
    "- 재현율과 정밀도는 서로 보완적인 지표\n",
    "- 가장 좋은 성능 평가는 재현율과 정밀도 모두 높은 수치를 얻는 것이나, 둘 중 어느 한 평가 지표만 매우 높고 다른 수치는 매우 낮은 경우는 바람직하지 않음\n",
    "- sklearn은 정밀도 계산을 위해 precision_score(), 재현율 계산을 위해 recall_score() API 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384bf2aa-9cee-4233-b5ff-13ee57330e47",
   "metadata": {},
   "source": [
    "- 평가를 간단하게 적용하기 위해 confusion matrix, accuracy, precision, recall 등의 평가를 한꺼번에 호출하는 get_clf_eval() 함수 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c575c5f4-c538-4f9f-9a9e-a6ac351af8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test,pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'. format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7cbe3d-0555-4867-b259-6d7096775f46",
   "metadata": {},
   "source": [
    "- 타이타닉 데이터를 다시 로드한 후 가공해 로지스틱 회귀를 기반으로 타이타닉 생존자를 예측하고 각 평가 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b3396-e70f-4d8e-961d-746396a7ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 원본 데이터를 재로딩 하고, feature데이터 셋과 Label 데이터 셋 추출. \n",
    "titanic_df = pd.read_csv(r'C:\\Users\\이희원\\OneDrive\\바탕 화면\\EWHA\\4-1\\ESAA\\kaggle_data\\titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)\n",
    "\n",
    "### transform_features 오류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a3165-318d-4489-b285-1eeafb0b8bf4",
   "metadata": {},
   "source": [
    "- 정밀도에 비해 재현율이 낮게 나옴 => 재현율 또는 정밀도를 강화할 방법?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd2670-f894-4e5b-8316-a559b2bc49fa",
   "metadata": {},
   "source": [
    "### 3.1 정밀도/재현율 트레이드오프"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e7378-90e1-42d0-9d26-9c3e9a02abab",
   "metadata": {},
   "source": [
    "- 분류하려는 업무 특성상 정밀도 or 재현율이 특별히 강조돼야 할 경우 분류의 결정 임곗값(threshold)을 조정해 정밀도 or 재현율 수치를 높일 수 있음\n",
    "- BUT 둘은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 높이면 나머지 한쪽은 떨어짐 (Trade-off)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41d32a-a3a7-4771-a464-85f796892c70",
   "metadata": {},
   "source": [
    "- predict_proba()\n",
    "  - 개별 데이터별로 예측 확률을 반환\n",
    "  - 학습이 완료된 사이킷런 Classifier 객체에서 호출 가능\n",
    "  - 테스트 피처 데이터 세트를 파라미터로 입력 시, 테스트 피처 레코드의 개별 클래스 예측 확률을 반환\n",
    "  - predict() 메서드와 유사 BUT 반환 결과가 예측 결과 클래스값이 나닌 예측 확률 결과임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7bfed-55f7-42ba-b5e9-c47327a516a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba() 결과 Shape: {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array와 예측 결괏값 array를 병함(concatenate)해 예측 확률과 결괏값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc31837-53bb-4d02-ba1f-9dab4760ca88",
   "metadata": {},
   "source": [
    "- 반환 결과인 ndarray는 0과 1에 대한 확률을 나타냄 => (첫 번째 칼럼 값) + (두 번째 칼럼 값) = 1\n",
    "- 두 개의 칼럼 중에서 더 큰 확률 값으로 predict() 메서드가 최종 예측\n",
    "- predict()\n",
    "  - predict_proba() 메서드에 기반해 생성된 API\n",
    "  - predict_proba() 호출 결과로 반환된 배열에서 분류 결정 임계값보다 큰 값이 들어 있는 칼럼의 위치를 받아서 최종적으로 예측 클래스를 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c52e31-dec6-4256-917f-480c139b7e28",
   "metadata": {},
   "source": [
    "##### [다음 예제]\n",
    "- threshold 변수를 특정 값으로 설정\n",
    "- Binarizer 클래스를 객체로 생성\n",
    "- 생성된 Binarizer 객체의 fit_transform() 메서드를 이용해 넘파이 ndarray를 입력하면\\\n",
    "  입력된 ndarray의 값을 지정된 threshold보다 같거나 작으면 0값으로, 크면 1값으로 변환해 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27ff80ca-ebcf-4e67-a722-84cc27d8102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1, -1, 2],\n",
    "     [2, 0, 0],\n",
    "     [0, 1.1, 1.2]]\n",
    "\n",
    "# X의 개별 원소들이 threshold 값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a81f63-f83d-4b73-a190-1cd7d13af449",
   "metadata": {},
   "source": [
    "- 이제 이 Binarizer를 이용해 사이킷런 predict()의 의사(pseudo) 코드 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf083da5-137a-4beb-9357-78428e0f0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold 설정값, 분류 결정 임곗값임\n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환값의 두 번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55500c8c-8652-40ea-a88e-18d09ca8e1b9",
   "metadata": {},
   "source": [
    "- 이 의사 코드로 계산된 평가 지표는 앞 예제의 타이타닉 데이터로 학습된 로지스틱 회귀 Classifier 객체에서 호출된 predict()로 계산된 지표 값과 정확히 일치 <= predict()가 predict_proba()에 기반함\n",
    "- 이 분류 결정 임곗값을 낮추면 평가 지표가 어떻게 변할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d26a1-326b-463b-ae42-4d608501a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤\n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "cusotm_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb2317-e31e-40c1-9c6f-3642d190dc56",
   "metadata": {},
   "source": [
    "- 임곗값을 낮춘 결과 재현율이 올라가고 정밀도가 떨어짐\n",
    "- WHY?: 분류 결정 임곗값은 Positive 예측값을 결정하는 확률의 기준. 즉, 임곗값이 떨어지면 Positive로 예측을 더 너그럽게 하는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500fe92c-cb33-4115-a612-25061eca3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 임곗값을 0.4에서부터 0.6까지 0.05씩 증가시키며 평가 지표를 조사: get_eval_by_threshold() 사용\n",
    "\n",
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장\n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    # thresholds list 객체 내의 값을 차례로 iteration하면서 Evaluation 수행\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefacf36-c59f-400a-83a4-a200a51d1215",
   "metadata": {},
   "source": [
    "- precision_recall_curve(): 지금까지 임곗값 변화에 따른 평가 지표 값을 알아보는 코드를 작성했는데, 사이킷런에서 제공하는 이와 유사한 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6cfea-d037-46e2-b2aa-cd1cc57b3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일 때의 예측 확률을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 실제값 데이터 세트와 레이블 값이 1일 때의 예측 활률을 precision_recall_curve 인자로 입력\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
    "\n",
    "# 반환된 임곗값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 step으로 추출\n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값:', np.round(threshold[thr_index], 2))\n",
    "\n",
    "# 15 step 단위로 추출된 임곗값에 따른 정밀도와 재현율 값\n",
    "print('샘플 임곗값별 정밀도:', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임곗값별 재현율:', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b4ed7-0262-42d9-8296-884142ccffb3",
   "metadata": {},
   "source": [
    "- 임곗값이 증가할수록 정밀도 값은 동시에 높아지나 재현율 값은 낮아짐\n",
    "- precision_recall_curve(): 정밀도와 재현율의 임곗값에 따른 값 변화를 곡선 형태의 그래프로 시각화하는 데 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b28dd0aa-3f4c-4bbe-bc9c-278a7f0d42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7f26b-c696-4933-9bdb-f254a15b38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출\n",
    "    precisions, recalls, thresholds = precision_recall_cruve(y_test, pred_proba_c1)\n",
    "\n",
    "    # X출을 threshold 값으로, Y 축은 정밀도, 재현율 값으로 각각 Plot 수행, 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = threshold.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
    "\n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "\n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a597d2-c3e3-46c7-8d8d-e27b90a53e43",
   "metadata": {},
   "source": [
    "[그래프 결과 해석]\n",
    "- 정밀도는 점선, 재현율은 실선으로 표현됨\n",
    "- 임곗값이 낮을수록 많은 수의 양성 예측으로 인해 재현율 값이 극도로 높아지고 정밀도 값이 극도로 낮아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28c71da-05cb-4ee1-a04c-87a297bd5fab",
   "metadata": {},
   "source": [
    "### 3.2 정밀도와 재현율의 맹점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea5aee-49f9-4a5a-8147-3a5ba2d996d9",
   "metadata": {},
   "source": [
    "- 정밀도와 재현율을 조정하기 위한 임곗값 변경은 업무 환경에 맞게 두 개의 수치를 상호 보완할 수 있는 수준해서 적용되어야 함. 단순히 하나의 성능 지표 수치를 높이기 위한 수단으로 사용되면 안 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06486b55-5cc7-4290-a879-24b4da6c53e7",
   "metadata": {},
   "source": [
    "#### 3.2.1 정밀도가 100%가 되는 방법 (bad case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e1049-67f3-4f1b-ba88-5a43a5fc0921",
   "metadata": {},
   "source": [
    "- 확실한 기준이 되는 경우만 Positive로 예측하고 나머지는 모두 Negative로 예측\n",
    "- ex. 환자가 80세 이상이고 비만이며 이전에 암 진단을 받았고 암 세포의 크기가 상위 0.1% 이상이면 무조건 Positive, 다른 경우는 Negative로 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b26a2a-c0f1-462b-bd4c-6c19a4b6a33e",
   "metadata": {},
   "source": [
    "#### 3.2.2 재현율이 100%가 되는 방법 (bad case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6b022-be50-403c-b799-5077ac3e6cca",
   "metadata": {},
   "source": [
    "- 모든 환자를 Positive로 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21a759-c73d-48e3-8d32-02b6bb972bed",
   "metadata": {},
   "source": [
    "## 4. F1 스코어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7926e4b1-bcbd-4264-82c8-4709f8ea140b",
   "metadata": {},
   "source": [
    "- 정밀도와 재현율을 결합한 지표\n",
    "- 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가짐\n",
    "- f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4e6c0-d0c9-4168-bfe0-e466dd6438fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, pred)\n",
    "print('F1 스코어: {0:.4f}', format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069bd235-d4f7-4379-9550-43d9065de81c",
   "metadata": {},
   "source": [
    "[타이타닉 생존자 예측에서 임곗값을 변화시키면서 F1 스코어를 포함한 평가 지표 구하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395af73-a989-4054-aac6-7c3275140067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
