{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBwSfGLo6XdyL5thTNaoEA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/levynlee/ESAA/blob/main/1014_%ED%95%84%EC%82%AC%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CH9. 추천 시스템**"
      ],
      "metadata": {
        "id": "ng27GKD-kYsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. 추천 시스템의 개요와 배경**"
      ],
      "metadata": {
        "id": "SdxpDUzekYqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.1 추천 시스템의 개요**"
      ],
      "metadata": {
        "id": "y9p9MJ8ykYo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "추천 시스템은 사용자 자신도 좋아하는지 몰랐던 취향을 시스템이 발견하고 그에 맞는 콘텐츠를 추천해준다는 점에서 의미가 있다. 더 많은 데이터가 추천 시스템에 축적되면서 추천이 더욱 정확해지고 다양한 결과를 얻을 수 있는 좋은 선순환 시스템을 구축할 수 있게 된다."
      ],
      "metadata": {
        "id": "j7cd1z6T1t3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.2 온라인 스토어의 필수 용소, 추천 시스템**"
      ],
      "metadata": {
        "id": "48hGuA11kYm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "추천 시스템을 구성하는 데 사용될 수 있는 데이터\n",
        "- 사용자가 어떤 상품을 구매했는가?\n",
        "- 사용자가 어떤 상품을 둘러보거나 장바구니에 넣었는가?\n",
        "- 사용자가 평가한 영화 평점은? 제품 평가는?\n",
        "- 사용자가 스스로 작성한 자신의 취향은?\n",
        "- 사용자가 무엇을 클릭했는가?"
      ],
      "metadata": {
        "id": "UCkj1FVI2kQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.3 추천 시스템의 유형**"
      ],
      "metadata": {
        "id": "2JkeACQ3kYlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기반 필터링(Content based filtering) 방식  \n",
        "\n",
        "협업 필터링(Collaborative filtering) 방식\n",
        "- 최근접 이웃(Nearest Neighbor) 협업 필터링\n",
        "- 잠재 요인(Latent Factor) 협업 필터링"
      ],
      "metadata": {
        "id": "SUgaOV1U5F3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. 콘텐츠 기반 필터링 추천 시스템**"
      ],
      "metadata": {
        "id": "niAqy1YukYjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "콘텐츠 기반 필터링 방식: 사용자가 특정한 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 다른 아이템을 추천하는 방식  \n",
        "- eg) 사용자가 특정 영화에 높은 평점을 줬다면 그 영화의 장르, 출연 배우, 감독, 영화 키워드 등의 콘텐츠와 유사한 다른 영화를 추천해주는 방식"
      ],
      "metadata": {
        "id": "WfUfUdrw5ZXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. 최근접 이웃 협업 필터링**"
      ],
      "metadata": {
        "id": "2-gDxAIikYhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "협업 필터링\n",
        "- 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식만을 기반으로 추천을 수행하는 것\n",
        "- 주요 목표: 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 예측 평가하는 것\n"
      ],
      "metadata": {
        "id": "9_g8-DuN5ubQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4. 잠재 요인 협업 필터링**"
      ],
      "metadata": {
        "id": "a2mSlRhekYfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.1 잠재 요인 협업 필터링의 이해**"
      ],
      "metadata": {
        "id": "yOxEijufkYd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "잠재 요인 협업 필터링\n",
        "- 사용자-아이템 평점 매트릭스 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법"
      ],
      "metadata": {
        "id": "DcDby1St6TXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.2 행렬 분해의 이해**"
      ],
      "metadata": {
        "id": "ViOgzDK0kYb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "행렬 분해\n",
        "- 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법\n",
        "- 대표적으로 SVD(Singular Vector Decomposition), NMF(Non-Negative Matrix Factorization) 등이 있다."
      ],
      "metadata": {
        "id": "celk3vYS6t2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.3 확률적 경사 하강법을 이용한 행렬 분해**"
      ],
      "metadata": {
        "id": "33ZGuX3-kYaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "P와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 P와 Q를 유추해내는 것  \n",
        "\n",
        "확률적 경사 하강법 (SGD)을 이용한 행렬 분해의 절차  \n",
        "1. P와 Q를 임의의 값을 가진 행렬로 설정한다.\n",
        "2. P와 Q.T 값을 곱해 예측 R 행렬을 계산하고 예측 R 행렬과 실제 R 행렬에 해당하는 오류 값을 계산한다.\n",
        "3. 이 오류 값을 최소화할 수 있도록 P와 Q 행렬을 적절한 값으로 각각 업데이트한다.\n",
        "4. 만족할 만한 오류 값을 가질 때까지 2, 3번 작업을 반복하면서 P와 Q 값을 업데이트해 근사화한다."
      ],
      "metadata": {
        "id": "7UxK-09D6tWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재 요인 차원 K는 3으로 설정.\n",
        "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
        " [np.NaN, 5, np.NaN, 3, 1 ],\n",
        "  [np.NaN, np.NaN, 3, 4, 4],\n",
        "   [5, 2, 1, 2, np.NaN]])\n",
        "num_users, num_items = R.shape\n",
        "K=3\n",
        "\n",
        "# P와 Q 행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력합니다.\n",
        "np.random.seed(1)\n",
        "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
        "Q = np.random.normal(scale=1./K, size=(num_items, K))"
      ],
      "metadata": {
        "id": "I84GLweIlOqM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R, P, Q, non_zeros):\n",
        "  error = 0\n",
        "  # 두 개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
        "  full_pred_matrix = np.dot(P, Q.T)\n",
        "\n",
        "  # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출해 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "  x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
        "  y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
        "  R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
        "  full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
        "  mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "caclBfxMlro8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장.\n",
        "non_zeros = [(i, j, R[i, j]) for i in range(num_users) for j in range(num_items) if R[i, j]>0]\n",
        "\n",
        "steps = 1000\n",
        "learning_rate = 0.01\n",
        "r_lambda = 0.01\n",
        "\n",
        "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트.\n",
        "for step in range(steps):\n",
        "  for i, j, r in non_zeros:\n",
        "    # 실제 값과 예측 값의 차이인 오류 값 구함\n",
        "    eij = r - np.dot(P[i, :], Q[j, :].T)\n",
        "    # Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i, :] = P[i, :] + learning_rate * (eij * Q[j, :] - r_lambda * P[i, :])\n",
        "    Q[j, :] = Q[j, :] + learning_rate * (eij * P[i, :] - r_lambda * Q[j, :])\n",
        "\n",
        "    rmse = get_rmse(R, P, Q, non_zeros)\n",
        "    if (step % 50) == 0:\n",
        "      print(\"### iteration step: \", step, \"rmse :\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxwGRZgIzvTn",
        "outputId": "1f46b0d2-fee9-4e37-a3cc-1ac2917f5c14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### iteration step:  0 rmse : 3.261355059488935\n",
            "### iteration step:  0 rmse : 3.26040057174686\n",
            "### iteration step:  0 rmse : 3.253984404542389\n",
            "### iteration step:  0 rmse : 3.2521583839863624\n",
            "### iteration step:  0 rmse : 3.252335303789125\n",
            "### iteration step:  0 rmse : 3.251072196430487\n",
            "### iteration step:  0 rmse : 3.2492449982564864\n",
            "### iteration step:  0 rmse : 3.247416477570409\n",
            "### iteration step:  0 rmse : 3.241926055455223\n",
            "### iteration step:  0 rmse : 3.2400454107613084\n",
            "### iteration step:  0 rmse : 3.240166740749792\n",
            "### iteration step:  0 rmse : 3.2388050277987723\n",
            "### iteration step:  50 rmse : 0.5003190892212748\n",
            "### iteration step:  50 rmse : 0.5001616291326989\n",
            "### iteration step:  50 rmse : 0.49899601202578087\n",
            "### iteration step:  50 rmse : 0.4988483450145831\n",
            "### iteration step:  50 rmse : 0.49895189256631756\n",
            "### iteration step:  50 rmse : 0.49833236830090993\n",
            "### iteration step:  50 rmse : 0.4984148489378701\n",
            "### iteration step:  50 rmse : 0.49792599580240876\n",
            "### iteration step:  50 rmse : 0.4900605568692785\n",
            "### iteration step:  50 rmse : 0.4890370238665435\n",
            "### iteration step:  50 rmse : 0.48869176023997846\n",
            "### iteration step:  50 rmse : 0.4876723101369648\n",
            "### iteration step:  100 rmse : 0.15911521988578564\n",
            "### iteration step:  100 rmse : 0.1588091617801093\n",
            "### iteration step:  100 rmse : 0.1587409221708901\n",
            "### iteration step:  100 rmse : 0.1582856952842508\n",
            "### iteration step:  100 rmse : 0.1583080948216876\n",
            "### iteration step:  100 rmse : 0.15828832993767403\n",
            "### iteration step:  100 rmse : 0.15787486893092847\n",
            "### iteration step:  100 rmse : 0.15792073606567072\n",
            "### iteration step:  100 rmse : 0.15725245215457084\n",
            "### iteration step:  100 rmse : 0.15710664164665206\n",
            "### iteration step:  100 rmse : 0.15690252144190003\n",
            "### iteration step:  100 rmse : 0.1564340384819247\n",
            "### iteration step:  150 rmse : 0.07546004875264435\n",
            "### iteration step:  150 rmse : 0.07544589133447106\n",
            "### iteration step:  150 rmse : 0.07543234329653023\n",
            "### iteration step:  150 rmse : 0.07514800672233914\n",
            "### iteration step:  150 rmse : 0.07518867696418177\n",
            "### iteration step:  150 rmse : 0.0752288950993841\n",
            "### iteration step:  150 rmse : 0.07489318864469259\n",
            "### iteration step:  150 rmse : 0.07493400425933257\n",
            "### iteration step:  150 rmse : 0.07462695506527872\n",
            "### iteration step:  150 rmse : 0.07464332131959663\n",
            "### iteration step:  150 rmse : 0.0746444164156341\n",
            "### iteration step:  150 rmse : 0.07455141311978046\n",
            "### iteration step:  200 rmse : 0.04361016579439073\n",
            "### iteration step:  200 rmse : 0.04370913068953006\n",
            "### iteration step:  200 rmse : 0.04369072102767977\n",
            "### iteration step:  200 rmse : 0.043475549832271414\n",
            "### iteration step:  200 rmse : 0.0435313092537358\n",
            "### iteration step:  200 rmse : 0.04359240037575283\n",
            "### iteration step:  200 rmse : 0.04329647906053838\n",
            "### iteration step:  200 rmse : 0.04332057192123618\n",
            "### iteration step:  200 rmse : 0.04310448294502512\n",
            "### iteration step:  200 rmse : 0.04313550286658552\n",
            "### iteration step:  200 rmse : 0.04313786864806258\n",
            "### iteration step:  200 rmse : 0.04325226798579314\n",
            "### iteration step:  250 rmse : 0.029395183185609734\n",
            "### iteration step:  250 rmse : 0.02954402948437167\n",
            "### iteration step:  250 rmse : 0.02950187436758184\n",
            "### iteration step:  250 rmse : 0.029329609713572593\n",
            "### iteration step:  250 rmse : 0.02940211807327667\n",
            "### iteration step:  250 rmse : 0.02946720568417511\n",
            "### iteration step:  250 rmse : 0.029189294191791375\n",
            "### iteration step:  250 rmse : 0.029198757426747605\n",
            "### iteration step:  250 rmse : 0.028995742260002243\n",
            "### iteration step:  250 rmse : 0.02904415445054541\n",
            "### iteration step:  250 rmse : 0.029049587101179365\n",
            "### iteration step:  250 rmse : 0.029248328780878973\n",
            "### iteration step:  300 rmse : 0.022678715233749362\n",
            "### iteration step:  300 rmse : 0.022844873864300484\n",
            "### iteration step:  300 rmse : 0.022773566650325074\n",
            "### iteration step:  300 rmse : 0.02263234507322516\n",
            "### iteration step:  300 rmse : 0.02272006255153119\n",
            "### iteration step:  300 rmse : 0.022778917442558434\n",
            "### iteration step:  300 rmse : 0.022516243062381223\n",
            "### iteration step:  300 rmse : 0.022515508246519694\n",
            "### iteration step:  300 rmse : 0.02229491665298542\n",
            "### iteration step:  300 rmse : 0.022367287171783136\n",
            "### iteration step:  300 rmse : 0.022392303480653113\n",
            "### iteration step:  300 rmse : 0.022621116143829466\n",
            "### iteration step:  350 rmse : 0.019516973680183715\n",
            "### iteration step:  350 rmse : 0.019681605297160464\n",
            "### iteration step:  350 rmse : 0.019585635379668415\n",
            "### iteration step:  350 rmse : 0.01946716545524988\n",
            "### iteration step:  350 rmse : 0.01956568678979253\n",
            "### iteration step:  350 rmse : 0.019614020075870497\n",
            "### iteration step:  350 rmse : 0.019368393329296258\n",
            "### iteration step:  350 rmse : 0.019361014872334943\n",
            "### iteration step:  350 rmse : 0.019116038405167533\n",
            "### iteration step:  350 rmse : 0.01920981547997513\n",
            "### iteration step:  350 rmse : 0.019255623979392192\n",
            "### iteration step:  350 rmse : 0.019493636196525135\n",
            "### iteration step:  400 rmse : 0.01803666559195465\n",
            "### iteration step:  400 rmse : 0.01819133106334419\n",
            "### iteration step:  400 rmse : 0.018078504374883574\n",
            "### iteration step:  400 rmse : 0.01797554592952707\n",
            "### iteration step:  400 rmse : 0.018080509676855847\n",
            "### iteration step:  400 rmse : 0.018118882879536648\n",
            "### iteration step:  400 rmse : 0.017889686482489363\n",
            "### iteration step:  400 rmse : 0.017878066671070433\n",
            "### iteration step:  400 rmse : 0.01761224433968553\n",
            "### iteration step:  400 rmse : 0.01772096734904666\n",
            "### iteration step:  400 rmse : 0.01778179645659777\n",
            "### iteration step:  400 rmse : 0.018022719092132704\n",
            "### iteration step:  450 rmse : 0.017334045429542092\n",
            "### iteration step:  450 rmse : 0.01747683493759156\n",
            "### iteration step:  450 rmse : 0.01735361907510825\n",
            "### iteration step:  450 rmse : 0.017260553985290646\n",
            "### iteration step:  450 rmse : 0.01736909385010645\n",
            "### iteration step:  450 rmse : 0.017399933857257726\n",
            "### iteration step:  450 rmse : 0.01718431757863743\n",
            "### iteration step:  450 rmse : 0.01716990649625117\n",
            "### iteration step:  450 rmse : 0.01688861579579296\n",
            "### iteration step:  450 rmse : 0.017006638154083088\n",
            "### iteration step:  450 rmse : 0.01707679250866153\n",
            "### iteration step:  450 rmse : 0.01731968595344266\n",
            "### iteration step:  500 rmse : 0.016991609248052833\n",
            "### iteration step:  500 rmse : 0.01712340891578616\n",
            "### iteration step:  500 rmse : 0.01699398405641037\n",
            "### iteration step:  500 rmse : 0.01690707049203008\n",
            "### iteration step:  500 rmse : 0.01701760577221745\n",
            "### iteration step:  500 rmse : 0.017043277556700362\n",
            "### iteration step:  500 rmse : 0.01683803145900356\n",
            "### iteration step:  500 rmse : 0.016821674312725313\n",
            "### iteration step:  500 rmse : 0.016529281264429145\n",
            "### iteration step:  500 rmse : 0.0166528887951985\n",
            "### iteration step:  500 rmse : 0.016728541275490984\n",
            "### iteration step:  500 rmse : 0.016973657887570753\n",
            "### iteration step:  550 rmse : 0.016818969716266233\n",
            "### iteration step:  550 rmse : 0.016941445597444732\n",
            "### iteration step:  550 rmse : 0.0168082592988841\n",
            "### iteration step:  550 rmse : 0.016725234339747562\n",
            "### iteration step:  550 rmse : 0.01683693849143515\n",
            "### iteration step:  550 rmse : 0.016859187050621206\n",
            "### iteration step:  550 rmse : 0.016661644526141564\n",
            "### iteration step:  550 rmse : 0.01664385102006508\n",
            "### iteration step:  550 rmse : 0.016343446075494233\n",
            "### iteration step:  550 rmse : 0.01647044082182643\n",
            "### iteration step:  550 rmse : 0.01654932331426952\n",
            "### iteration step:  550 rmse : 0.016796804595895633\n",
            "### iteration step:  600 rmse : 0.016727439717439115\n",
            "### iteration step:  600 rmse : 0.016842259158977232\n",
            "### iteration step:  600 rmse : 0.016706687924467476\n",
            "### iteration step:  600 rmse : 0.016626255644609397\n",
            "### iteration step:  600 rmse : 0.016738696939262717\n",
            "### iteration step:  600 rmse : 0.016758682415985614\n",
            "### iteration step:  600 rmse : 0.0165668572000528\n",
            "### iteration step:  600 rmse : 0.016547954461110684\n",
            "### iteration step:  600 rmse : 0.016241668760761063\n",
            "### iteration step:  600 rmse : 0.016370800056137867\n",
            "### iteration step:  600 rmse : 0.016451627209257007\n",
            "### iteration step:  600 rmse : 0.01670132290188466\n",
            "### iteration step:  650 rmse : 0.016674291334806343\n",
            "### iteration step:  650 rmse : 0.016782895588885082\n",
            "### iteration step:  650 rmse : 0.016645698091647773\n",
            "### iteration step:  650 rmse : 0.01656714079916223\n",
            "### iteration step:  650 rmse : 0.016680091021598568\n",
            "### iteration step:  650 rmse : 0.016698554271430792\n",
            "### iteration step:  650 rmse : 0.016511017732427972\n",
            "### iteration step:  650 rmse : 0.016491228766905293\n",
            "### iteration step:  650 rmse : 0.01618054419796173\n",
            "### iteration step:  650 rmse : 0.01631111150707529\n",
            "### iteration step:  650 rmse : 0.01639316772050061\n",
            "### iteration step:  650 rmse : 0.01664473691247669\n",
            "### iteration step:  700 rmse : 0.0166383624426085\n",
            "### iteration step:  700 rmse : 0.016741936743323586\n",
            "### iteration step:  700 rmse : 0.016603524189001625\n",
            "### iteration step:  700 rmse : 0.016526454393300468\n",
            "### iteration step:  700 rmse : 0.016639792083379498\n",
            "### iteration step:  700 rmse : 0.016657201345297346\n",
            "### iteration step:  700 rmse : 0.016472928381641428\n",
            "### iteration step:  700 rmse : 0.01645241257047358\n",
            "### iteration step:  700 rmse : 0.016138379086448083\n",
            "### iteration step:  700 rmse : 0.016269993747904915\n",
            "### iteration step:  700 rmse : 0.01635288508504558\n",
            "### iteration step:  700 rmse : 0.016605910068210026\n",
            "### iteration step:  750 rmse : 0.01660906046895522\n",
            "### iteration step:  750 rmse : 0.016708562969098305\n",
            "### iteration step:  750 rmse : 0.016569153528341783\n",
            "### iteration step:  750 rmse : 0.016493367054249922\n",
            "### iteration step:  750 rmse : 0.016607027966870924\n",
            "### iteration step:  750 rmse : 0.01662368102752549\n",
            "### iteration step:  750 rmse : 0.016441927271724666\n",
            "### iteration step:  750 rmse : 0.0164208024653437\n",
            "### iteration step:  750 rmse : 0.016104179990850755\n",
            "### iteration step:  750 rmse : 0.016236628551952913\n",
            "### iteration step:  750 rmse : 0.016320141009292095\n",
            "### iteration step:  750 rmse : 0.016574200475705\n",
            "### iteration step:  800 rmse : 0.016581161561119846\n",
            "### iteration step:  800 rmse : 0.016677363428436936\n",
            "### iteration step:  800 rmse : 0.016537069269613652\n",
            "### iteration step:  800 rmse : 0.0164624613777787\n",
            "### iteration step:  800 rmse : 0.016576412350487568\n",
            "### iteration step:  800 rmse : 0.01659250180024954\n",
            "### iteration step:  800 rmse : 0.01641271740942833\n",
            "### iteration step:  800 rmse : 0.016391072859801518\n",
            "### iteration step:  800 rmse : 0.01607242307736876\n",
            "### iteration step:  800 rmse : 0.016205589842521878\n",
            "### iteration step:  800 rmse : 0.016289609430091494\n",
            "### iteration step:  800 rmse : 0.01654431582921597\n",
            "### iteration step:  850 rmse : 0.01655222898431553\n",
            "### iteration step:  850 rmse : 0.01664575121547569\n",
            "### iteration step:  850 rmse : 0.016504627328190514\n",
            "### iteration step:  850 rmse : 0.016431145801748863\n",
            "### iteration step:  850 rmse : 0.016545370571042432\n",
            "### iteration step:  850 rmse : 0.016561024020105147\n",
            "### iteration step:  850 rmse : 0.016382795627019747\n",
            "### iteration step:  850 rmse : 0.016360700076085824\n",
            "### iteration step:  850 rmse : 0.016040446344395578\n",
            "### iteration step:  850 rmse : 0.016174269580681345\n",
            "### iteration step:  850 rmse : 0.016258737354641353\n",
            "### iteration step:  850 rmse : 0.01651375177473524\n",
            "### iteration step:  900 rmse : 0.016521280433777957\n",
            "### iteration step:  900 rmse : 0.016612624200841405\n",
            "### iteration step:  900 rmse : 0.016470695682261876\n",
            "### iteration step:  900 rmse : 0.016398314989165292\n",
            "### iteration step:  900 rmse : 0.016512806333073466\n",
            "### iteration step:  900 rmse : 0.01652811087350182\n",
            "### iteration step:  900 rmse : 0.016351122754892394\n",
            "### iteration step:  900 rmse : 0.016328629783842166\n",
            "### iteration step:  900 rmse : 0.016007096878603234\n",
            "### iteration step:  900 rmse : 0.016141544071514122\n",
            "### iteration step:  900 rmse : 0.016226430843994055\n",
            "### iteration step:  900 rmse : 0.01648146573819501\n",
            "### iteration step:  950 rmse : 0.016488081335748316\n",
            "### iteration step:  950 rmse : 0.016577652134974717\n",
            "### iteration step:  950 rmse : 0.01643492933498176\n",
            "### iteration step:  950 rmse : 0.0163636366204062\n",
            "### iteration step:  950 rmse : 0.01647839195954869\n",
            "### iteration step:  950 rmse : 0.01649340903060659\n",
            "### iteration step:  950 rmse : 0.016317416842511007\n",
            "### iteration step:  950 rmse : 0.016294568571753248\n",
            "### iteration step:  950 rmse : 0.015972009545965248\n",
            "### iteration step:  950 rmse : 0.0161070634587959\n",
            "### iteration step:  950 rmse : 0.016192355609214733\n",
            "### iteration step:  950 rmse : 0.016447171683479155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qvc28PeqkAHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321165ac-7914-4d40-875f-724a7897500c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 행렬:\n",
            " [[3.991 0.897 1.306 2.002 1.663]\n",
            " [6.696 4.978 0.979 2.981 1.003]\n",
            " [6.677 0.391 2.987 3.977 3.986]\n",
            " [4.968 2.005 1.006 2.017 1.14 ]]\n"
          ]
        }
      ],
      "source": [
        "pred_matrix = np.dot(P, Q.T)\n",
        "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
      ]
    }
  ]
}